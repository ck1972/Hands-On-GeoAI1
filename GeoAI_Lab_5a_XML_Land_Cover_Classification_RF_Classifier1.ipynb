{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ck1972/Hands-On-GeoAI1/blob/main/GeoAI_Lab_5a_XML_Land_Cover_Classification_RF_Classifier1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explainable Machine Learning in Geospatial Analysis: Land Cover Classification**\n",
        "\n",
        "## Introduction\n",
        "Explainable ML methods are essential for interpreting the decision-making processes of complex or \"black-box\" models. They help identify the most influential input features driving model predictions, thereby enhancing the transparency, interpretability, and trustworthiness of machine learning outcomes."
      ],
      "metadata": {
        "id": "9enVF7go_Y6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup\n",
        "### Import libraries\n",
        "Import the necessary libraries (pandas, numpy, scikit-learn, rasterio, etc.)."
      ],
      "metadata": {
        "id": "-pwDPkalAvRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import shap"
      ],
      "metadata": {
        "id": "F6bfz1KZzA-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive\n",
        "Next, mount your Google Drive. You will be prompted to authorize access to your Google Drive. Once mounted, you can read/write files in /content/drive/MyDrive."
      ],
      "metadata": {
        "id": "bzVfa9mtzRMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VXvi8JvIzRmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define paths and variables\n",
        "Define the the paths to access your own directory structure in Google Drive. In this tutorial, we use a CSV training dataset (Bul_TrainingData_2024.csv) containing pixel values and their corresponding classes. We will also define the paths to the training datasets and random forest model.\n"
      ],
      "metadata": {
        "id": "l0HWzfHGzVCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path that contains the datasets\n",
        "Sample_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2025/Bul_TA_S2_Pal_2025.csv'\n",
        "MODEL_PATH = '/content/drive/MyDrive/Bulawayo_Dataset_2025/best_rf_model.pkl'"
      ],
      "metadata": {
        "id": "Vj2kFuhMzVd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define target and predictor variables\n",
        "Next, define and specify the overall structure of the land cover classification task. Bands lists the Sentinel-2 spectral bands (e.g., B2, B3, B4) used as input features (predictors) for the model, while LC indicates the target column named “class.”"
      ],
      "metadata": {
        "id": "xaZUI5eOz8PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target and predictor variables\n",
        "features = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12', 'HV']  # Feature columns\n",
        "label = ['class']\n",
        "\n",
        "Classes = [0, 1, 2, 3, 4, 5]\n",
        "N_Classes = 6\n",
        "Names   = [\"Bare area\", \"Built-up\", \"Cropland\", \"Grassland\", \"Woodland\", \"Water\"]\n",
        "Palette = [\n",
        "    '#D3D3D3',  # grey for class 0 (Bare area)\n",
        "    '#FF0000',  # red for class 1 (Built-up)\n",
        "    '#FFD700',  # gold for class 2 (Cropland)\n",
        "    '#ADFF2F',  # greenyellow for class 3 (Grassland)\n",
        "    '#006400',  # darkgreen for class 4 (Woodland)\n",
        "    '#0000FF'   # blue for class 5 (Water)\n",
        "]"
      ],
      "metadata": {
        "id": "WjFAe4hjM2VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Load and Prepare Training Data\n",
        "Next, load and prepare the training data. The training data is in a CSV format with columns for each band (B2, B3, etc.) and a class column (land cover type)."
      ],
      "metadata": {
        "id": "ZmtsZJvI3q4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data as a DataFrame\n",
        "df = pd.read_csv(Sample_Path)\n",
        "\n",
        "# Inspect first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Separate features (X) and label (y)\n",
        "X = df[features]\n",
        "y = df['class']\n",
        "\n",
        "# Ensure no missing values\n",
        "print(f\"Missing values in features: {X.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in label: {y.isnull().sum()}\")\n",
        "\n",
        "# Split into training and testing subsets\n",
        "# (you can also do cross-validation if you prefer)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "TcAThBNC3rQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Explainable Machine Learning (xML)\n",
        "### Introduction\n",
        "We will use xML methods such as  SHAP (Shapley Additive exPlanations) model to gain insights in the random forest model.\n",
        "\n",
        "Let's start by loading and extracting the saved random forest model from the dictionary."
      ],
      "metadata": {
        "id": "HKr7p6Snh51x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "package = joblib.load(MODEL_PATH)\n",
        "rf_model = package[\"model\"]\n",
        "features = package[\"features\"]\n",
        "label = package[\"label\"]\n",
        "\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "id": "v82c5DFZh-f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest feature importance\n",
        "Display the gloabl random forest feature importance."
      ],
      "metadata": {
        "id": "MOzU6-KY5DjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest feature importance\n",
        "# Get feature importances\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot feature importances using Seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')\n",
        "plt.title('Random Forest Feature Importance')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QtHQkQNq5D76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest feature importance\n",
        "Plot random forest feature importance per land cover class."
      ],
      "metadata": {
        "id": "lA66fBCY5_Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "from collections import defaultdict\n",
        "\n",
        "# Number of features and classes\n",
        "n_features = len(features)\n",
        "n_classes = len(Names)\n",
        "\n",
        "# Initialize a matrix to accumulate weighted importances\n",
        "class_importance_matrix = np.zeros((n_classes, n_features))\n",
        "\n",
        "# Loop over all trees in the forest\n",
        "for estimator in rf_model.estimators_:\n",
        "    importances = estimator.feature_importances_  # (n_features,)\n",
        "\n",
        "    # Estimate class probabilities from this tree on training samples\n",
        "    tree = estimator.tree_\n",
        "    value_at_root = tree.value[0][0]  # shape: (n_classes,)\n",
        "    class_prob = value_at_root / value_at_root.sum()  # Normalize\n",
        "\n",
        "    # Add weighted importances to each class\n",
        "    for class_idx in range(n_classes):\n",
        "        class_importance_matrix[class_idx] += class_prob[class_idx] * importances\n",
        "\n",
        "# Normalize importance within each class\n",
        "class_importance_matrix = class_importance_matrix / class_importance_matrix.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Build long-form DataFrame for plotting\n",
        "importance_data = []\n",
        "for class_idx, class_name in enumerate(Names):\n",
        "    for feat_idx, feat in enumerate(features):\n",
        "        importance_data.append({\n",
        "            \"Class\": class_name,\n",
        "            \"Feature\": feat,\n",
        "            \"Importance\": class_importance_matrix[class_idx, feat_idx]\n",
        "        })\n",
        "\n",
        "importance_by_class_df = pd.DataFrame(importance_data)"
      ],
      "metadata": {
        "id": "BLmZIS-H6sGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the random forest feature importance per class."
      ],
      "metadata": {
        "id": "IiR_pF596u6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the figure\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(\n",
        "    data=importance_by_class_df,\n",
        "    x=\"Importance\",\n",
        "    y=\"Feature\",\n",
        "    hue=\"Class\",\n",
        "    palette=Palette\n",
        ")\n",
        "plt.title(\"Random Forest Feature Importance by Land Cover Class (Soft Aggregation)\")\n",
        "plt.xlabel(\"Normalized Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.legend(title=\"Land Cover Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cW-FbxR68sh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP (SHapley Additive exPlanations) method\n",
        "Next, we will use the SHAP method. The SHAP (SHapley Additive exPlanations) method is based on the shapley values, which is a concept from cooperative game theory proposed by Lloyd Shapley (1953).\n",
        "\n",
        "Let's create an explainer for the RF model. Explainer prints useful information, especially for resolving potential errors."
      ],
      "metadata": {
        "id": "x_GS7_ypiNx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 1,000 rows from the training data for explainability\n",
        "X_train_sample = X_train.sample(n=1000, random_state=42)\n",
        "\n",
        "# Create SHAP explainer using the smaller sample\n",
        "explainer = shap.TreeExplainer(rf_model)\n",
        "\n",
        "# Compute SHAP values for the sample only\n",
        "shap_values = explainer(X_train_sample)"
      ],
      "metadata": {
        "id": "4v2HKbvmiTcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP summary plot\n",
        "Finally, display SHAP summary plot to gain insights into the random forest model for only 1000 pixel samples."
      ],
      "metadata": {
        "id": "oabXRnQRCZoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ListedColormap class to create custom colormaps\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Define a custom color palette corresponding to different land cover classes\n",
        "Palette = [\n",
        "    '#FFD700',  # gold - e.g., Cropland\n",
        "    '#ADFF2F',  # greenyellow - e.g., Grassland\n",
        "    '#FF0000',  # red - e.g., Built-up\n",
        "    '#D3D3D3',  # grey - e.g., Bare area\n",
        "    '#006400',  # darkgreen - e.g., Woodland\n",
        "    '#0000FF'   # blue - e.g., Water\n",
        "]\n",
        "\n",
        "# Convert the list of hex colors into a matplotlib colormap\n",
        "my_cmap = ListedColormap(Palette)\n",
        "\n",
        "# Generate a SHAP summary plot to interpret feature importance\n",
        "shap.summary_plot(\n",
        "    shap_values,        # SHAP values for the model predictions\n",
        "    X_train_sample,     # Subsample of training features\n",
        "    feature_names=features,   # Names of the input features\n",
        "    class_names=Names,        # Descriptive labels for each class\n",
        "    color=my_cmap             # Use the custom colormap for class coloring\n",
        ")"
      ],
      "metadata": {
        "id": "BAioYmwACZ-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SHAP Beeswarm plots by land cover class\n",
        "Finally, generate individual SHAP beeswarm plots for each land cover class. This enables visualization of how each input feature such as spectral bands and backscatter contributes to the model's prediction for a specific class. We begin by looping through all defined land cover classes (Names) and, for each class, extracts the corresponding SHAP values using the third dimension ([..., class_index]) of the shap_values array. A new shap.Explanation object is then constructed for each class to retain essential metadata like base values and feature names. The shap.summary_plot() function is called with plot_type=\"dot\" to produce a beeswarm plot for the current class. In these plots, each point represents a feature’s SHAP value for a single sample, illustrating both the relative importance of the feature (based on the spread) and the direction of its effect (positive or negative) on the model’s output. This approach provides a clear and interpretable breakdown of the most influential features driving the classification of each land cover type."
      ],
      "metadata": {
        "id": "BBnJRzTX28rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each class index and plot a class-specific beeswarm\n",
        "for class_index, class_name in enumerate(Names):\n",
        "    print(f\"Generating SHAP beeswarm plot for class: {class_name}\")\n",
        "\n",
        "    # Extract SHAP values for the given class\n",
        "    shap_class_values = shap.Explanation(\n",
        "        values=shap_values.values[..., class_index],\n",
        "        base_values=shap_values.base_values[..., class_index],\n",
        "        data=shap_values.data,\n",
        "        feature_names=shap_values.feature_names\n",
        "    )\n",
        "\n",
        "    # Plot class-specific beeswarm\n",
        "    shap.summary_plot(\n",
        "        shap_class_values,\n",
        "        X_train_sample,\n",
        "        plot_type=\"dot\",\n",
        "        show=True\n",
        "    )"
      ],
      "metadata": {
        "id": "sQgdfijt3Llk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}