{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ck1972/Hands-On-GeoAI1/blob/main/GeoAI_Lab_2b_Preparing_Data_for_Geospatial_Machine_Learning_S2_Palsar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SncSpvGm2VUS"
      },
      "source": [
        "# **Preparing Training Data for Land Cover Mapping: Optical and SAR data**\n",
        "## Introduction\n",
        "The aim of this tutorial is to prepare high-quality training data for land cover mapping by integrating Sentinel-2 optical imagery with ALOS-PALSAR radar data. Combining these two complementary datasets enhances the ability to distinguish between different land cover types, especially in areas where where radar backscatter provides valuable structural information.\n",
        "\n",
        "### Check tutorial for preparing training data (polygons)\n",
        "- Watch Youtube video tutorial: https://www.youtube.com/watch?v=k--M1a-V_x4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoerQ1ama7Fh"
      },
      "source": [
        "## Initialize and authenticate Earth Engine\n",
        "To get started with Google Earth Engine (GEE), you need to initialize and authenticate the Earth Engine API. Follow these steps.\n",
        "\n",
        "\n",
        "First, import the Earth Engine API by importing the ee module into your Python environment. This module allows you to interact with the Earth Engine platform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7a6_vlZcOZPU"
      },
      "outputs": [],
      "source": [
        "# Import the API\n",
        "import ee\n",
        "\n",
        "# Import the geemap library\n",
        "import geemap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V9idAmhc8X7"
      },
      "source": [
        "Next, initialize the Earth Engine API. You must initialize the API to use Earth Engine functionalities. This involves authenticating your session and initializing the library. When you run the ee.Initialize() command for the first time, you might be prompted to authenticate your session. This will open a web browser window where you need to log in with your Google account and grant Earth Engine access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0hGRqMB4PN7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e69e45d1-c5bc-4501-f105-a6c5b325776d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='ee-kamusoko-test') # Change to your EE project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import study area boundary\n",
        "First, import the study area boundary."
      ],
      "metadata": {
        "id": "6rzLzHwHHyNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the boundary\n",
        "boundary = ee.FeatureCollection('users/kamas72_ML_Zim_Cities/Bulawayo_Crop_Boundary')"
      ],
      "metadata": {
        "id": "ixeL13nmHreX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import training data\n",
        "Next, we will import land cover training data (polygons), which was created in QGIS."
      ],
      "metadata": {
        "id": "76K5l09OI7zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training datasets\n",
        "training_data = ee.FeatureCollection('projects/ee-kamusoko-test/assets/Bul_TrainingData_2025a')\n",
        "\n",
        "# Get the histogram of classes (key = class value, value = count)\n",
        "histogram = training_data.aggregate_histogram('Cl_Id').getInfo()\n",
        "\n",
        "# Define a label map for clarity\n",
        "label_map = {\n",
        "    '0': \"Bare areas\",\n",
        "    '1': \"Built-up\",\n",
        "    '2': \"Cropland\",\n",
        "    '3': \"Grass / open areas\",\n",
        "    '4': \"Woodlands\",\n",
        "    '5': \"Water\"\n",
        "}\n",
        "\n",
        "print(\"Number of training polygons per land cover class (Cl_Id):\")\n",
        "for cl_id in sorted(histogram.keys(), key=int):\n",
        "    label = label_map.get(cl_id, f\"Class {cl_id}\")\n",
        "    print(f\"{label} (Cl_Id={cl_id}): {histogram[cl_id]}\")"
      ],
      "metadata": {
        "id": "wy3ft4D1JRu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Sentinel-2 composite\n",
        "The sentinel-2 mission offers a wide-swath, high-resolution, multispectral imaging capability with a global 5-day revisit frequency. The Sentinel-2 Multispectral Instrument (MSI) has 13 spectral bands, providing a comprehensive view of the Earth's surface. These bands are distributed as four at 10 meters, six at 20 meters, and three at 60 meters spatial resolution. For more detailed information about the Sentinel-2 mission, please visit https://sentinel.esa.int/web/sentinel/missions/sentinel-2.\n"
      ],
      "metadata": {
        "id": "fQtiCfzBjCBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentinel-2 SR data (Harmonized)\n",
        "s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
        "\n",
        "# Cloud masking function using SCL band\n",
        "def mask_s2clouds(image):\n",
        "    scl = image.select('SCL')\n",
        "    mask = scl.neq(8).And(scl.neq(9)).And(scl.neq(10)).And(scl.neq(11))\n",
        "    return image.updateMask(mask).divide(10000)\n",
        "\n",
        "# Filter and preprocess Sentinel-2 data\n",
        "S2 = (s2.filterBounds(boundary)\n",
        "      .filterDate('2025-03-01', '2025-06-30')\n",
        "      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
        "      .map(mask_s2clouds)\n",
        "      .select(['B2','B3','B4','B5','B6','B7','B8','B11','B12']))\n",
        "\n",
        "# Bands to include in the classification\n",
        "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12']\n",
        "\n",
        "# Create a median composite\n",
        "composite = S2.median().clip(boundary)"
      ],
      "metadata": {
        "id": "YHrK17UDj542"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create ALOS PALSAR-2 ScanSAR composite\n",
        "ALOS PALSAR-2 (Advanced Land Observing Satellite â€“ Phased Array type L-band Synthetic Aperture Radar) is a Japanese L-band radar sensor (Japan Aerospace Exploration Agency). The ScanSAR mode allows wide-area coverage (up to 350 km swath) by scanning multiple sub-swaths, making it useful for regional-scale monitoring. It operates in L-band, which penetrates vegetation and soil, making it ideal for forest mapping, flood detection, and land deformation studies. The 25 m PALSAR-2 ScanSAR (Google Earth Engine catalog) is normalized backscatter data of PALSAR-2 broad area observation mode with observation width of 350 km. The SAR imagery was ortho-rectificatied and slope corrected using the ALOS World 3D - 30 m (AW3D30) Digital Surface Model. Polarization data are stored as 16-bit digital numbers (DN).\n",
        "\n",
        "We will normalize the PALSAR backscatter values (HH and HV) to the range [0, 1] in Earth Engine, you can use .unitScale(min, max). For ALOS PALSAR backscatter in DN (digital number) format, typical values range from 0 to 8000."
      ],
      "metadata": {
        "id": "ObXExkUz_7Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ALOS PALSAR-2 ScanSAR image collection and filter by boundary and date\n",
        "collection = (\n",
        "    ee.ImageCollection('JAXA/ALOS/PALSAR-2/Level2_2/ScanSAR')\n",
        "    .filterBounds(boundary)\n",
        "    .filterDate('2025-03-01', '2025-06-30')\n",
        ")\n",
        "\n",
        "# Compute median composites for HH and HV\n",
        "Palsar_median_HH = collection.select('HH').median().clip(boundary).unitScale(0, 8000)\n",
        "Palsar_median_HV = collection.select('HV').median().clip(boundary).unitScale(0, 8000)"
      ],
      "metadata": {
        "id": "jcM2eg59_8E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Sentinel-1 Image Collection and filter by bounds, metadata, and date (Not available)\n",
        "collection_S1 = (\n",
        "    ee.ImageCollection('COPERNICUS/S1_GRD')\n",
        "    .filterBounds(boundary)\n",
        "    .filterMetadata('instrumentMode', 'equals', 'IW')\n",
        "    .filterDate('2025-03-01', '2025-06-30')\n",
        ")\n",
        "\n",
        "# Filter for dual polarization (VV and VH)\n",
        "collection_S1_VV_VH = (\n",
        "    collection_S1\n",
        "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
        "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
        ")\n",
        "\n",
        "# Filter for ascending orbit\n",
        "collection_S1_ASC = collection_S1_VV_VH.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n",
        "\n",
        "# Compute median composites for VV and VH\n",
        "S1_median_ASC_VV = collection_S1_ASC.select('VV').median().clip(boundary)\n",
        "S1_median_ASC_VH = collection_S1_ASC.select('VH').median().clip(boundary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dPHl4-cWBvdo",
        "outputId": "55ffb57e-4980-446b-f237-0c4e18d13514"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display training samples and satellite imagery\n",
        "Next, display the land cover training samples on the satellite imagery (Sentinel-2 and ALOS PALSAR)."
      ],
      "metadata": {
        "id": "gEgM_Yg7r3nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the map\n",
        "map = geemap.Map()\n",
        "map.centerObject(training_data, 12)\n",
        "\n",
        "# Add Sentinel-2 composite\n",
        "map.addLayer(composite, {'bands': ['B11', 'B8', 'B3'], 'min': 0, 'max': 0.3}, 'Sentinel-2 Composite')\n",
        "\n",
        "# Add PALSAR ScanScar layers to the map\n",
        "map.addLayer(Palsar_median_HH, {'min': 0, 'max': 1}, 'PALSAR Median HH')\n",
        "map.addLayer(Palsar_median_HV, {'min': 0, 'max': 1}, 'PALSAR Median HV')\n",
        "\n",
        "# Add VV and VH layers to map\n",
        "#map.addLayer(S1_median_ASC_VV, {'min': -15, 'max': 5}, 'S-1 Median Asc VV')\n",
        "#map.addLayer(S1_median_ASC_VH, {'min': -25, 'max': 5}, 'S-1 Median Asc VH')\n",
        "\n",
        "# Add training data as a layer\n",
        "map.addLayer(training_data, {'color': 'red'}, 'Training Data')\n",
        "\n",
        "# Display the map with layer control\n",
        "map.addLayerControl()\n",
        "map"
      ],
      "metadata": {
        "id": "L0jVI-EZoOYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare training data\n",
        "In this step, we prepare the dataset for training and testing machine learning models by processing satellite imagery and training labels. We start by selecting Sentinel-2 bands (B2 to B12) and clipping the composite image to the specified boundary region, defining the input features. Next, we rasterize the vector training data using the Cl_Id property to create a raster layer representing class labels and add it as a new band (class) to the input features. To create a representative dataset, we use stratified sampling to extract reflectance values and class labels, ensuring proportional representation across classes."
      ],
      "metadata": {
        "id": "eUAu9jH49iyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Sentinel-2 composite with PALSAR HV band\n",
        "combined = composite.addBands(Palsar_median_HV.rename('HV'))\n",
        "\n",
        "# Use ee.List for band selection\n",
        "bands = ee.List(['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12', 'HV'])\n",
        "input_features = combined.clip(boundary)\n",
        "print('input features: ', input_features.getInfo())\n",
        "\n",
        "# Rasterise training data\n",
        "training_rasterized = training_data.reduceToImage(\n",
        "    properties=['Cl_Id'],\n",
        "    reducer=ee.Reducer.first()\n",
        ").toInt().remap([0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]) # Bare areas, Built-up, Cropland, Grass/ open areas, Woodlands, Water\n",
        "\n",
        "# Add a class band to features\n",
        "input_features = input_features.addBands(training_rasterized.toInt().rename('class'))\n",
        "\n",
        "# Sample the reflectance, elevation, and slope values for each training point\n",
        "training_dataset = input_features.stratifiedSample(\n",
        "    numPoints=10000,\n",
        "    classBand=\"class\",\n",
        "    region=boundary,\n",
        "    scale=20\n",
        ")"
      ],
      "metadata": {
        "id": "dxvkaFEP9jp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export the training points\n",
        "We export the 'training_data' feature collection, Sentinel-2 composite and PALSAR ScanSAR images to your Google Drive. After configuring the export, the task is started with task.start()."
      ],
      "metadata": {
        "id": "GPIPLBF45Ahj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export training samples as CSV\n",
        "task_table = ee.batch.Export.table.toDrive(\n",
        "    collection=training_dataset,\n",
        "    description='Bul_TA_S2_Pal_2025',\n",
        "    folder='Bulawayo_Dataset_2025',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "\n",
        "# Start the export task\n",
        "task_table.start()\n",
        "\n",
        "# Export the composite with indices\n",
        "task_composite = ee.batch.Export.image.toDrive(\n",
        "    image=composite.float(),\n",
        "    description='Bul_S2_2025',\n",
        "    folder='Bulawayo_Dataset_2025',\n",
        "    scale=10,\n",
        "    region=boundary.geometry(),\n",
        "    maxPixels=1e13\n",
        ")\n",
        "task_composite.start()\n",
        "\n",
        "# Export the composite with indices\n",
        "task_composite = ee.batch.Export.image.toDrive(\n",
        "    image=Palsar_median_HV.float(),\n",
        "    description='Bul_Palsar_HV_2025',\n",
        "    folder='Bulawayo_Dataset_2025',\n",
        "    scale=10,\n",
        "    region=boundary.geometry(),\n",
        "    maxPixels=1e13\n",
        ")\n",
        "task_composite.start()"
      ],
      "metadata": {
        "id": "I5OQCrvJtSsF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI9zXnwsSDAyNJrxh4oZbW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}