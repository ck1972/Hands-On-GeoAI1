{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ck1972/Hands-On-GeoAI1/blob/main/GeoAI_Lab_3b_Land_Cover_Classification_with_Machine_Learning_Classifiers_GitHub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Land Cover Classification Using Random Forest Classifier, Optical and SAR Imagery**\n",
        "\n",
        "## Introduction\n",
        "This lab will use a random forest classifier to classify optical (Sentinel-2) and SAR (ALOS PALSAR ScanSAR HV polarization) images. The goal is to improve land cover classification by combining optical and SAR imagery."
      ],
      "metadata": {
        "id": "98VODWhEJzmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup\n",
        "### Install libraries\n",
        "First, install any additional libraries that are not installed by default (e.g., rasterio, earthpy).."
      ],
      "metadata": {
        "id": "-pwDPkalAvRb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWr5V6krNx-I",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install rasterio and earthpy libraries\n",
        "!pip install rasterio\n",
        "!pip install earthpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n",
        "Import the necessary libraries (pandas, numpy, scikit-learn, rasterio, etc.)."
      ],
      "metadata": {
        "id": "SIhoHLoHq8_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import earthpy.plot as ep\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "import seaborn as sns\n",
        "import joblib"
      ],
      "metadata": {
        "id": "F6bfz1KZzA-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive\n",
        "Next, mount your Google Drive. You will be prompted to authorize access to your Google Drive. Once mounted, you can read/write files in /content/drive/MyDrive."
      ],
      "metadata": {
        "id": "bzVfa9mtzRMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VXvi8JvIzRmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define paths and variables\n",
        "Define the the paths to access your own directory structure in Google Drive. In this tutorial, we use:\n",
        "-A CSV training dataset (Bul_TrainingData_2024.csv) containing pixel values and their corresponding classes.\n",
        "- A multiband Sentinel-2 image (Bul_S2_2024.tif).\n",
        "- PALSAR ScanSAR polarization"
      ],
      "metadata": {
        "id": "l0HWzfHGzVCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path that contains the datasets\n",
        "Sample_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2025/Bul_TA_S2_Pal_2025.csv'\n",
        "S2_Image_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2025/Bul_S2_2025.tif'\n",
        "Palsar_Image_Path = '/content/drive/MyDrive/Bulawayo_Dataset_2025/Bul_Palsar_HV_2025.tif'"
      ],
      "metadata": {
        "id": "Vj2kFuhMzVd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define target and predictor variables\n",
        "Next, define and specify the overall structure of the land cover classification task. Bands lists the Sentinel-2 spectral bands (e.g., B2, B3, B4) used as input features (predictors) for the model, while LC indicates the target column named “class.” Classes is a list of integer codes that the model will learn to predict, and N_Classes denotes the total number of these categories. The Names list provides descriptive labels (e.g., “Bare area,” “Built-up”) that match each code, making it easier to interpret results. Finally, Palette is a set of hex color codes for visualizing each class in plots or exported maps."
      ],
      "metadata": {
        "id": "xaZUI5eOz8PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target and predictor variables\n",
        "Bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12', 'HV']  # Feature columns\n",
        "LC = ['class']\n",
        "\n",
        "Classes = [0, 1, 2, 3, 4, 5]\n",
        "N_Classes = 6\n",
        "Names   = [\"Bare area\", \"Built-up\", \"Cropland\", \"Grassland\", \"Woodland\", \"Water\"]\n",
        "Palette = [\n",
        "    '#D3D3D3',  # grey for class 0 (Bare area)\n",
        "    '#FF0000',  # red for class 1 (Built-up)\n",
        "    '#FFD700',  # gold for class 2 (Cropland)\n",
        "    '#ADFF2F',  # greenyellow for class 3 (Grassland)\n",
        "    '#006400',  # darkgreen for class 4 (Woodland)\n",
        "    '#0000FF'   # blue for class 5 (Water)\n",
        "]"
      ],
      "metadata": {
        "id": "WjFAe4hjM2VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Images\n",
        "We will use rasterio to open the .tif file. These are Sentinel-2 imagery and ALOS PALSAR ScanSAR HV polarization."
      ],
      "metadata": {
        "id": "GVQZaVjI3lT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Sentinel-2 image\n",
        "with rasterio.open(S2_Image_Path) as src_s2:\n",
        "    s2_array = src_s2.read()  # shape: [bands, height, width]\n",
        "    profile = src_s2.profile\n",
        "    height, width = src_s2.height, src_s2.width\n",
        "\n",
        "# Load PALSAR HV image\n",
        "with rasterio.open(Palsar_Image_Path) as src_palsar:\n",
        "    palsar_array = src_palsar.read(1)  # HV is single-band: [height, width]\n",
        "\n",
        "# Ensure shapes match\n",
        "assert s2_array.shape[1:] == palsar_array.shape, \"Image sizes don't match. Reproject or resample needed.\""
      ],
      "metadata": {
        "id": "9l9ogzuvbsSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display images\n",
        "Display the Sentinel-2 composite and the PALSAR ScanSAR HV polorization image."
      ],
      "metadata": {
        "id": "2YkbgnVoeWJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select bands for RGB composite: B4 (Red), B3 (Green), B2 (Blue)\n",
        "# Note: Check your band ordering if uncertain\n",
        "red = s2_array[2, :, :]  # B4\n",
        "green = s2_array[1, :, :]  # B3\n",
        "blue = s2_array[0, :, :]  # B2\n",
        "\n",
        "# Stack and normalize for RGB display\n",
        "rgb = np.stack([red, green, blue], axis=-1)\n",
        "rgb_min, rgb_max = 0, 0.3  # Adjust depending on your scaling\n",
        "rgb_display = np.clip((rgb - rgb_min) / (rgb_max - rgb_min), 0, 1)\n",
        "\n",
        "# Normalized HV (grayscale display)\n",
        "hv_min, hv_max = 0,1\n",
        "hv_display = np.clip((palsar_array - hv_min) / (hv_max - hv_min), 0, 1)\n",
        "\n",
        "# Plot side by side\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "axs[0].imshow(rgb_display)\n",
        "axs[0].set_title('Sentinel-2 RGB (B4, B3, B2)')\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow(hv_display, cmap='gray')\n",
        "axs[1].set_title('PALSAR HV Backscatter')\n",
        "axs[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xi6_Mmgvel1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Load and Prepare Training Data\n",
        "Next, load and prepare the training data. The training data is in a CSV format with columns for each band (B2, B3, etc.) and a class column (land cover type)."
      ],
      "metadata": {
        "id": "ZmtsZJvI3q4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data as a DataFrame\n",
        "df = pd.read_csv(Sample_Path)\n",
        "\n",
        "# Inspect first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Separate features (X) and label (y)\n",
        "X = df[Bands]\n",
        "y = df['class']\n",
        "\n",
        "# Ensure no missing values\n",
        "print(f\"Missing values in features: {X.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in label: {y.isnull().sum()}\")\n",
        "\n",
        "# Split into training and testing subsets\n",
        "# (you can also do cross-validation if you prefer)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "TcAThBNC3rQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "### Summary statistics\n",
        "Prepare summary statistics for the training dataset."
      ],
      "metadata": {
        "id": "I7VpO5TdjlCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics (mean, std, min, max, etc.)\n",
        "summary_stats = X.describe().transpose()\n",
        "summary_stats['missing_values'] = X.isnull().sum()\n",
        "summary_stats['data_type'] = X.dtypes\n",
        "print(\"Summary statistics for features:\")\n",
        "print(summary_stats)\n"
      ],
      "metadata": {
        "id": "cSbCciqH3LbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the class dsitribution\n",
        "Next, check the land cover distribution in the training dataset."
      ],
      "metadata": {
        "id": "hJDfwgmL3knD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map class numbers to names\n",
        "df['class_name'] = df['class'].map(dict(zip(Classes, Names)))\n",
        "\n",
        "# Class distribution (absolute counts and percentages)\n",
        "class_counts = df['class_name'].value_counts().sort_index()\n",
        "class_percent = df['class_name'].value_counts(normalize=True).sort_index() * 100\n",
        "\n",
        "# Combine into one table\n",
        "class_summary = pd.DataFrame({\n",
        "    'Class Name': class_counts.index,\n",
        "    'Count': class_counts.values,\n",
        "    'Percentage (%)': class_percent.values.round(2)\n",
        "})\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print(class_summary)"
      ],
      "metadata": {
        "id": "Ji6dqP6f3gjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Density plots\n",
        "Density plots help visualize the distribution of pixel values in each spectral band for each land cover class."
      ],
      "metadata": {
        "id": "zAOheSZ13BI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add readable class names\n",
        "df['class_name'] = df['class'].map(dict(zip(Classes, Names)))\n",
        "\n",
        "# Set up the 2x5 subplot grid for density plots\n",
        "fig, axes = plt.subplots(2, 5, figsize=(25, 10))\n",
        "fig.suptitle('Density Plots by Land Cover Class', fontsize=20)\n",
        "\n",
        "for i, band in enumerate(Bands):\n",
        "    ax = axes[i // 5, i % 5]\n",
        "    sns.kdeplot(\n",
        "        data=df,\n",
        "        x=band,\n",
        "        hue=\"class_name\",\n",
        "        fill=True,\n",
        "        common_norm=False,\n",
        "        alpha=0.4,\n",
        "        linewidth=1.2,\n",
        "        ax=ax,\n",
        "        palette=Palette\n",
        "    )\n",
        "    ax.set_title(f'Density Plot: {band}')\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Density')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Leave space for suptitle\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Irm1j5f6owqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Box plots\n",
        "\n",
        "Box plots help you see the median, quartiles, and potential outliers across land cover classes."
      ],
      "metadata": {
        "id": "baP4KXa1j10h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the 2x5 subplot grid for box plots\n",
        "fig, axes = plt.subplots(2, 5, figsize=(25, 10))\n",
        "fig.suptitle('Box Plots by Land Cover Class', fontsize=20)\n",
        "\n",
        "for i, band in enumerate(Bands):\n",
        "    ax = axes[i // 5, i % 5]\n",
        "    sns.boxplot(\n",
        "        data=df,\n",
        "        x=\"class_name\",\n",
        "        y=band,\n",
        "        hue=\"class_name\",           # <-- Add hue\n",
        "        palette=dict(zip(Names, Palette)),\n",
        "        legend=False,               # <-- Avoid legend on every plot\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f'Box Plot: {band}')\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vZSbqhihpoJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Violin plots\n",
        " Violin plots combine box plots and kernel density estimates, giving you more insight into both distribution shape and summary statistics (median, quartiles, etc.)"
      ],
      "metadata": {
        "id": "EV8zt45pp83A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Violin plots: 2 rows × 5 columns\n",
        "fig, axes = plt.subplots(2, 5, figsize=(25, 10))\n",
        "fig.suptitle('Violin Plots by Land Cover Class', fontsize=20)\n",
        "\n",
        "for i, band in enumerate(Bands):\n",
        "    ax = axes[i // 5, i % 5]\n",
        "    sns.violinplot(\n",
        "        data=df,\n",
        "        x=\"class_name\",\n",
        "        y=band,\n",
        "        hue=\"class_name\",\n",
        "        palette=dict(zip(Names, Palette)),\n",
        "        dodge=False,\n",
        "        ax=ax,\n",
        "        linewidth=1\n",
        "    )\n",
        "    ax.set_title(f'Violin Plot: {band}')\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Safe legend removal\n",
        "    if ax.get_legend() is not None:\n",
        "        ax.get_legend().remove()\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zNYS_yEGj88d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Notes*\n",
        "The width of the violin at any given point reflects the density of data points (or pixels, in the case of remote sensing). A wider section indicates that more observations fall within that range. A narrow neck in the violin shape suggests that the values are highly concentrated with low variation, while a wide base typically points to a long tail or spread in the data.\n",
        "\n",
        "At the center of the violin, you'll find a box plot representation. The white dot indicates the median value, providing a quick view of the central tendency of the distribution. The thick black bar represents the interquartile range (IQR), the middle 50% of the data, while the thin vertical line extending above and below the box shows the data's range, excluding potential outliers.\n",
        "\n",
        "The height of the violin itself shows the range of values a feature (or band) takes for a particular land cover class. A taller violin implies greater variability in that band for the class, while a shorter violin reflects more consistent or tightly clustered values. Collectively, these components make violin plots especially useful for assessing class separability, variability, and feature usefulness in classification tasks."
      ],
      "metadata": {
        "id": "KJjQosFftuXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation matrix\n",
        "\n",
        "This helps you understand the relationships among bands and HV."
      ],
      "metadata": {
        "id": "3beH3VFkkAb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute correlation matrix\n",
        "corr = df[Bands].corr()\n",
        "\n",
        "# Plot correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z4S1ADNmkGJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print correlations above 0.9."
      ],
      "metadata": {
        "id": "mCfWJ3oNueRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute correlation matrix\n",
        "corr = df[Bands].corr()\n",
        "\n",
        "# Select upper triangle of the correlation matrix (excluding diagonal)\n",
        "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "\n",
        "# Find and print pairs with correlation above 0.9\n",
        "high_corr = upper.stack()[upper.stack() > 0.9]\n",
        "\n",
        "print(\"Feature pairs with correlation > 0.9:\")\n",
        "print(high_corr)"
      ],
      "metadata": {
        "id": "JnRtFUZcuiBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate the Random Forest Classifier\n",
        "\n",
        "We will train the random forest and will compile accuracy metrics, confusion matrices, and classification reports."
      ],
      "metadata": {
        "id": "X-8ljFQc-x2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_preds = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "ftWuB56n-ySm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model validation\n",
        "Next, we will calculate model validation metrics for the random forest model."
      ],
      "metadata": {
        "id": "LSEEsDM_CyJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model\n",
        "models = {\n",
        "    \"Random Forest\": rf_preds\n",
        "}\n",
        "\n",
        "for name, preds in models.items():\n",
        "    print(f\"\\n** {name} **\")\n",
        "    print(\"Accuracy:\", (preds == y_test).mean())\n",
        "\n",
        "    # Classification Report\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, preds, labels=Classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Classes)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7h4sLGwuC0Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Best RF Model\n",
        "Let's save the best RF model parameters, feature names, or other metadata together.\n"
      ],
      "metadata": {
        "id": "MdjQxy9Ref_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model parameters\n",
        "model_package = {\n",
        "    \"model\": rf,            # your trained Random Forest model\n",
        "    \"features\": Bands,      # input feature names\n",
        "    \"label\": 'class'        # label column name\n",
        "}\n",
        "\n",
        "# Define model path\n",
        "MODEL_PATH = '/content/drive/MyDrive/Bulawayo_Dataset_2025/best_rf_model.pkl'\n",
        "joblib.dump(model_package, MODEL_PATH)\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pe8OLc4egqh",
        "outputId": "d9dcd4a7-9f62-479e-e60f-a76c374f9eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Land Cover Classification\n",
        "\n",
        "Next, we will use the random forest classifier to predict class labels for every pixel of the Sentinel-2 and ALOS PALSAR images.\n",
        "\n",
        "### i. Stack Sentinel-2 and PALSAR HV images"
      ],
      "metadata": {
        "id": "IFpqICff_ak-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack PALSAR HV as an extra band\n",
        "palsar_array_expanded = palsar_array[np.newaxis, :, :]  # shape: [1, height, width]\n",
        "combined_array = np.concatenate((s2_array, palsar_array_expanded), axis=0)  # shape: [bands+1, height, width]\n",
        "print(\"Combined array shape:\", combined_array.shape)"
      ],
      "metadata": {
        "id": "dAFvKpb9YMYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii. Reshape for prediction\n",
        "Scikit-Learn expects a 2D array for prediction, where each row corresponds to a pixel and each column corresponds to a band. Therefore, we need to reshape from (bands, height, width) to (height*width, bands) for input into Scikit-Learn."
      ],
      "metadata": {
        "id": "AlL8ULA-_luW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape for classification\n",
        "band_count = combined_array.shape[0]\n",
        "img_reshaped = combined_array.reshape(band_count, -1).T  # shape: [n_pixels, n_features]\n",
        "print(\"Reshaped array for prediction:\", img_reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPlHdUXoALMd",
        "outputId": "b0f6dd28-bb65-498f-cf69-9366aa93cb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped array for prediction: (23761673, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii.  Use the random forest for prediction\n",
        "Next, we will use the random forest for prediction. Finally, we will take a 1D array of predicted land cover classes and reshape it back into a 2D raster format (image) so it matches the original image's spatial dimensions."
      ],
      "metadata": {
        "id": "uyBBaiuWAOHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using trained RandomForest model (e.g. rf)\n",
        "prediction = rf.predict(img_reshaped)\n",
        "prediction = prediction.astype(np.uint8)\n",
        "\n",
        "# Reshape back to image\n",
        "prediction_map = prediction.reshape(height, width)"
      ],
      "metadata": {
        "id": "yvDw97oDAYwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the land cover map\n",
        "\n",
        "Next, visualize the resulting map with a color palette corresponding to each class ID."
      ],
      "metadata": {
        "id": "vxzKWUBiAcDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a discrete colormap\n",
        "# We need one more level than classes for from_levels_and_colors\n",
        "levels = Classes + [max(Classes) + 1]\n",
        "cmap, norm = from_levels_and_colors(levels, Palette)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "im = plt.imshow(prediction_map, cmap=cmap, norm=norm)\n",
        "plt.title(\"Land Cover Map\")\n",
        "\n",
        "# Create colorbar with a shrink factor (0.7 = 70% of default height)\n",
        "cbar = plt.colorbar(im, shrink=0.7)\n",
        "\n",
        "# Center tick labels\n",
        "tick_positions = [i + 0.5 for i in Classes]\n",
        "cbar.set_ticks(tick_positions)\n",
        "cbar.set_ticklabels(Names)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yLT-BbhQAkzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export the Land Cover Map\n",
        "We can save the land cover map to a new GeoTIFF using rasterio."
      ],
      "metadata": {
        "id": "Aft_fLsTAoUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predicted land cover map\n",
        "output_path = '/content/drive/MyDrive/Bulawayo_Dataset_2025/Bul_LC_RF_2025a.tif'\n",
        "with rasterio.open(\n",
        "    output_path, 'w',\n",
        "    driver='GTiff',\n",
        "    height=height,\n",
        "    width=width,\n",
        "    count=1,\n",
        "    dtype=np.uint8,\n",
        "    crs=profile['crs'],\n",
        "    transform=profile['transform']\n",
        ") as dst:\n",
        "    dst.write(prediction_map, 1)"
      ],
      "metadata": {
        "id": "sSzD142Gji8V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}