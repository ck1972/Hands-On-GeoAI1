{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND3OXP861eHj3DV513KYek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ck1972/Hands-On-GeoAI1/blob/main/GeoAI_Lab_5b_Explainable_Machine_Learning_for_RF_Regression_GitHub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Explainable Machine Learning for Random Forest Regression**\n",
        "\n",
        "## Introduction\n",
        "In the lab 4b, we modeled aboveground biomass density (AGBD) using GEDI Level 4A (L4A) data, Sentinel-2 (S2) spectral bands, and vegetation indices (NDVI, CCCI, and SLAVI), and a random forest regression model. The model showed high predictive power, with an R² score of 0.88."
      ],
      "metadata": {
        "id": "qaIj37rHLnbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting-up Colab\n",
        "### Mount your Google Drive\n",
        "First, make sure that your data is loaded in Google Drive. After that mount your Google Drive using the code below."
      ],
      "metadata": {
        "id": "RWmMpy2cX578"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pDbunkxcOhem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, import the required libraries"
      ],
      "metadata": {
        "id": "4Fpnsx7BYFXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "from sklearn.inspection import permutation_importance # PFI - Permutation Feature Importance\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "import seaborn as sns\n",
        "import joblib # Import joblib library"
      ],
      "metadata": {
        "id": "-N96dk4DOyUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define variables and paths\n",
        "Access the necessary datasets and then define the target (aboveground biomass density) and predictor variables (Sentinel-2 bands and vegetation indices)."
      ],
      "metadata": {
        "id": "mBvqJLR2YMRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target and predictor variables\n",
        "Target = ['agbd'] # target variable\n",
        "Predictors = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12','NDVI','CCCI','SLAVI'] # predictor variables\n",
        "SAMPLE_PATH = '/content/drive/My Drive/Maf_Datasets/Cleaned_GEDI_L4A_2022_Dataset1.csv' # With filtered agbd\n",
        "MODEL_PATH = '/content/drive/MyDrive/Maf_Datasets/rf_model1.pkl' # Define model path"
      ],
      "metadata": {
        "id": "qFRxmFbEPk7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import training datasets and split training data\n",
        "Next, we import the sample training dataset and split it into training and test datasets."
      ],
      "metadata": {
        "id": "zrflZDDQXuQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read sample\n",
        "samples = pd.read_csv(SAMPLE_PATH)[Predictors + Target]\n",
        "samples\n",
        "\n",
        "# Split into train and test\n",
        "train, test = train_test_split(samples, test_size=0.2, shuffle=True, random_state=42)\n",
        "\n",
        "# Get variables input and output\n",
        "X_train = train[Predictors]\n",
        "X_test = test[Predictors]\n",
        "y_train = train[Target].astype(float)\n",
        "y_test = test[Target].astype(float)\n",
        "\n",
        "# Show the data shape\n",
        "print(f'Train Predictors: {X_train.shape}\\nTest Predictors: {X_test.shape}\\nTrain Target: {y_train.shape}\\nTest Target: {y_test.shape}')"
      ],
      "metadata": {
        "id": "HG-vqhboPpKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Explainable Machine Learning (xML)\n",
        "### Introduction\n",
        "We will use xML techniques such as SHAP (Shapley Additive exPlanations) to gain insights in the random forest model.\n",
        "\n",
        "Let's start by loading and extracting the saved random forest model from the dictionary."
      ],
      "metadata": {
        "id": "Xz14TRg8Qz_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary\n",
        "model_package = joblib.load(MODEL_PATH)\n",
        "\n",
        "# Extract the actual Random Forest model\n",
        "loaded_rf_model = model_package[\"model\"]"
      ],
      "metadata": {
        "id": "G9Ek0ahhQ0Vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature importance\n",
        "Let's start by examing variable importance. Feature importance methods highlight the contribution of each input variable to the model’s prediction.\n",
        "\n",
        "### Mean Decrease Impurity (MDI)\n",
        "Mean Decrease Impurity (MDI) is a method used in decision tree-based models, such as random forests, to assess feature importance."
      ],
      "metadata": {
        "id": "LTGusEk1WeLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MDI - Mean Decrease Impurity from the loaded model\n",
        "mdi_importances = loaded_rf_model.feature_importances_\n",
        "\n",
        "# Create DataFrame for plotting\n",
        "mdi_df = pd.DataFrame({'Feature': Predictors, 'Importance': mdi_importances})\n",
        "mdi_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=mdi_df, palette='viridis')\n",
        "plt.title('MDI Feature Importance (Loaded Model)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4N1z5lDfWenr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP (SHapley Additive exPlanations) method\n",
        "Next, we will use the SHAP method. SHAP (SHapley Additive exPlanations) is a method that helps us understand how each feature contributes to a prediction made by a machine learning model."
      ],
      "metadata": {
        "id": "R1TnBr8kBLWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can use SHAP with the loaded model\n",
        "explainer = shap.Explainer(loaded_rf_model, X_train)\n",
        "shap_values = explainer(X_train, check_additivity=False)"
      ],
      "metadata": {
        "id": "tGFzbLB2Q2nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a beeswarm plot\n",
        "Next, we use the SHAP beeswarm plot function (shap.plots.beeswarm) to create a beeswarm plot that displays SHAP values."
      ],
      "metadata": {
        "id": "joFoj1dJT36M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "shap.plots.beeswarm(shap_values)"
      ],
      "metadata": {
        "id": "dxnNsdcRT4TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a layered plot\n",
        "We can also use the SHAP violin plot function (shap.plots.beeswarm) to create  a layered violin plot that displays SHAP values. The ***max_display=12*** argument limits the plot to the top 12 most important features"
      ],
      "metadata": {
        "id": "cqLKmoO1Vprm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Layered violin plot\n",
        "shap.plots.violin(shap_values, max_display=12)"
      ],
      "metadata": {
        "id": "hq89234BSDAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scatter plots\n",
        "Finally, we want to gain deeper insights into the relationship between 'B5', 'B6', 'B8', and 'B12' values with the target variable 'agbd' (Mg/ha) for the RF model.\n"
      ],
      "metadata": {
        "id": "n7YzO0rKPEBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract B5 , B6, B8 and B12 values from X_train based on features.\n",
        "B5_values = X_train.iloc[:, Predictors.index('B5')]\n",
        "B6_values = X_train.iloc[:, Predictors.index('B6')]\n",
        "B8_values = X_train.iloc[:, Predictors.index('B8')]\n",
        "B2_values = X_train.iloc[:, Predictors.index('B2')]\n",
        "\n",
        "# Predict the 'agbd' values using the trained RF model\n",
        "predicted_values = loaded_rf_model.predict(X_train)\n",
        "\n",
        "# Create subplots with one row and two columns\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 8))\n",
        "\n",
        "# Scatter plot for B5 values against 'abgd' values (Mg/ha)\n",
        "axes[0, 0].scatter(B5_values, y_train, color='blue', label='Reference')\n",
        "axes[0, 0].scatter(B5_values, predicted_values, color='red', label='Predicted')\n",
        "axes[0, 0].set_xlabel('Spectral reflectance')\n",
        "axes[0, 0].set_ylabel('AGBD (Mg/ha)')\n",
        "axes[0, 0].set_title('B5 Reference vs Predicted (RF Model)')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Scatter plot for B11 values against 'abgd' values (Mg/ha)\n",
        "axes[0, 1].scatter(B6_values, y_train, color='blue', label='Reference')\n",
        "axes[0, 1].scatter(B6_values, predicted_values, color='red', label='Predicted')\n",
        "axes[0, 1].set_xlabel('Spectral reflectance')\n",
        "axes[0, 1].set_ylabel('AGBD (Mg/ha)')\n",
        "axes[0, 1].set_title('B6 Reference vs Predicted (RF Model)')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Scatter plot for B8 values against 'abgd' values (Mg/ha)\n",
        "axes[1, 0].scatter(B8_values, y_train, color='green', label='Reference')\n",
        "axes[1, 0].scatter(B8_values, predicted_values, color='orange', label='Predicted')\n",
        "axes[1, 0].set_xlabel('Spectral reflectance')\n",
        "axes[1, 0].set_ylabel('AGBD (Mg/ha)')\n",
        "axes[1, 0].set_title('B8 Reference vs Predicted (RF Model)')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# Scatter plot for B2 values against 'abgd' values (Mg/ha)\n",
        "axes[1, 1].scatter(B2_values, y_train, color='green', label='Reference')\n",
        "axes[1, 1].scatter(B2_values, predicted_values, color='orange', label='Predicted')\n",
        "axes[1, 1].set_xlabel('Spectral reflectance')\n",
        "axes[1, 1].set_ylabel('AGBD (Mg/ha)')\n",
        "axes[1, 1].set_title('B2 Reference vs Predicted (RF Model)')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "# Adjust layout and display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BzmPZfWAPAjT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}