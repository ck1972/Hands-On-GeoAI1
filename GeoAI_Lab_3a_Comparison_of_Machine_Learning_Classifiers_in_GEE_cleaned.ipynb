{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ck1972/Hands-On-GeoAI1/blob/main/GeoAI_Lab_3a_Comparison_of_Machine_Learning_Classifiers_in_GEE_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9enVF7go_Y6x"
      },
      "source": [
        "# Comparing Machine Learning Classifiers in GEE: An Introductory Guide with Python\n",
        "## Introduction\n",
        "The script aims to compare minimum distance, k-nearest neighbor (KNN), support vector machines, decision trees, random forest,and gradient tree boosting classifiers in Google Earth Engine (GEE). We use Python in Colab.\n",
        "\n",
        "- Requirements\n",
        "To run this script, the user must have an Earth Engine account. In addition, the user must authenticate the Earth Engine Python API. See the instructions [here](https://developers.google.com/earth-engine/guides/auth).\n",
        "- This script will use the [geemap](https://geemap.org) Python package to visualize, and map land cover.\n",
        "\n",
        "Following are the steps to compare the machine learning classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAAjR3HqAaef"
      },
      "source": [
        "# Initialize and Authenticate Earth Engine\n",
        "To get started with Google Earth Engine (GEE), you need to initialize and authenticate the Earth Engine API. Follow these steps.\n",
        "\n",
        "\n",
        "First, import the Earth Engine API by importing the ee module into your Python environment. This module allows you to interact with the Earth Engine platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B4EYlLWYAZ-S"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import ee\n",
        "import geemap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF3CjTkeAkX_"
      },
      "source": [
        "Next, initialize the Earth Engine API. You must initialize the API to use Earth Engine functionalities. This involves authenticating your session and initializing the library. When you run the ee.Initialize() command for the first time, you might be prompted to authenticate your session. This will open a web browser window where you need to log in with your Google account and grant Earth Engine access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXK5JCrdAqOD"
      },
      "outputs": [],
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='ee-kamusoko-test') # Change to your EE project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYreBcfdBO90"
      },
      "source": [
        "## Import the project boundary\n",
        "First, import the study area boundary boundary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZfRakIzN8HE"
      },
      "outputs": [],
      "source": [
        "# Load the boundary\n",
        "boundary = ee.FeatureCollection('users/kamas72_ML_Zim_Cities/Bulawayo_Crop_Boundary')\n",
        "\n",
        "# Load training datasets\n",
        "# training_areas = ee.FeatureCollection('users/kamas72_ML_Zim_Cities/Updated_TA_2020_Bul_May_21_GEE')\n",
        "training_areas = ee.FeatureCollection('projects/ee-kamusoko-test/assets/Bul_TrainingData_2025a')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ivWK_RlBe2W"
      },
      "source": [
        "## Prepare Sentinel-2 imagery\n",
        "First, preprocess Sentinel-2 imagery by first applying cloud masking to remove cloud and cirrus pixels using the QA60 band. Then load Sentinel-2 surface reflectance images within a specified date range and filters them based on cloud cover, retaining images with less than 20% cloudiness. A median composite is generated from the filtered images and clipped to a specified boundary region. Finally, the composite is visualized as a false-color image using selected bands on an interactive map, complete with layer control for enhanced usabilit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BkBt9EIPDIy"
      },
      "outputs": [],
      "source": [
        "# Function for Cloud Masking\n",
        "def mask_s2clouds(image):\n",
        "    qa = image.select('QA60')\n",
        "    cloudBitMask = ee.Number(2).pow(10).int()\n",
        "    cirrusBitMask = ee.Number(2).pow(11).int()\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "    return image.updateMask(mask).divide(10000)\n",
        "\n",
        "# Load Sentinel-2\n",
        "s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "    .filterDate('2025-03-01', '2025-06-30') \\\n",
        "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \\\n",
        "    .map(mask_s2clouds) \\\n",
        "    .select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12'])\n",
        "\n",
        "# Clip the composite\n",
        "composite = s2.median().clip(boundary)\n",
        "\n",
        "# Print Sentinel-2 Composite\n",
        "print('Sentinel-2 Composite:', composite.getInfo())\n",
        "\n",
        "# Display the Sentinel-2 composite\n",
        "# Initialize the map\n",
        "map1 = geemap.Map()\n",
        "\n",
        "# Add the composite image to the map with specified display settings.\n",
        "map1.addLayer(composite, {'bands': ['B11', 'B8', 'B3'], 'min': 0, 'max': 0.3}, 'Sentinel-2 Composite')\n",
        "\n",
        "# Display the map with layer control.\n",
        "map1.centerObject(boundary, 12)\n",
        "map1.addLayerControl()\n",
        "map1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCY0sdg4VW8N"
      },
      "source": [
        "## Prepare training data\n",
        "In this step, we prepare the dataset for training and testing machine learning models by processing satellite imagery and training labels. We start by selecting Sentinel-2 bands (B2 to B12) and clipping the composite image to the specified boundary region, defining the input features. Next, we rasterize the vector training data using the Cl_Id property to create a raster layer representing class labels and add it as a new band (class) to the input features. To create a representative dataset, we use stratified sampling to extract reflectance values and class labels, ensuring proportional representation across classes. A random column is added to the dataset with a fixed seed for reproducibility, allowing us to split the data into 70% for training and 30% for validation. Finally, we confirm the dataset sizes to ensure the split is as intended. This process prepares the data for effective training and validation of machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k4xvzbtPGiC"
      },
      "outputs": [],
      "source": [
        "# Use ee.List for band selection\n",
        "bands = ee.List(['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B11', 'B12'])\n",
        "input_features = composite.clip(boundary)\n",
        "print('input features: ', input_features.getInfo())\n",
        "\n",
        "# Rasterise training data\n",
        "training_rasterized = training_areas.reduceToImage(\n",
        "    properties=['Cl_Id'],\n",
        "    reducer=ee.Reducer.first()\n",
        ").toInt().remap([0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]) # Bare areas, Built-up, Cropland, Grass/ open areas, Woodlands, Water\n",
        "\n",
        "# Add a class band to features\n",
        "input_features = input_features.addBands(training_rasterized.toInt().rename('class'))\n",
        "\n",
        "# Sample the reflectance, elevation, and slope values for each training point\n",
        "training_dataset = input_features.stratifiedSample(\n",
        "    numPoints=10000,\n",
        "    classBand=\"class\",\n",
        "    region=boundary,\n",
        "    scale=20\n",
        ")\n",
        "\n",
        "# Add a random column (named random) and specify seed value for repeatability\n",
        "training_dataset = training_dataset.randomColumn('random', 50)\n",
        "\n",
        "# Split into training and testing (validation) sets\n",
        "split = 0.7  # Split the training dataset into 70% training and 30% testing (validation)\n",
        "Sample_training = training_dataset.filter(ee.Filter.lt('random', split))\n",
        "Sample_test = training_dataset.filter(ee.Filter.gte('random', split))\n",
        "\n",
        "# Print the training and testing (validation data)\n",
        "print(\"Number of training pixels:\", Sample_training.size().getInfo())\n",
        "print(\"Number of validation pixels:\", Sample_test.size().getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m14YwlA1Vf3V"
      },
      "source": [
        "## Function for training machine learning classifiers\n",
        "Next, we define and train multiple classifiers for satellite image classification. A helper function, train_classifier, is created to train any classifier using the specified training dataset. It requires three inputs: the classifier, the training dataset, and the input bands. The function uses the train method to associate class labels (classProperty) with the selected input bands (inputProperties). Four classifiers are initialized: a decision tree (smileCart), a random forest (smileRandomForest with 100 trees),a support vector machine classifier (SVM with an RBF kernel and gamma parameter of 0.5), and a gradient tree boost classifier (smileGradientTreeBoost with parameters such as shrinkage and sampling rate). These classifiers can be trained on the dataset and later used for image classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioq-FI4TPLIU"
      },
      "outputs": [],
      "source": [
        "# Create a function for training classifiers\n",
        "def train_classifier(classifier, training_data):\n",
        "    return classifier.train(\n",
        "        features=training_data,\n",
        "        classProperty='class',\n",
        "        inputProperties=bands\n",
        "    )\n",
        "\n",
        "knn_classifier = ee.Classifier.smileKNN(k=5)  # K-Nearest Neighbors with k=5\n",
        "rbf_svc_classifier = ee.Classifier.libsvm(kernelType='RBF', gamma=0.5) # Support vector machines\n",
        "dt_classifier = ee.Classifier.smileCart() # CART decision tree\n",
        "rf_classifier = ee.Classifier.smileRandomForest(100) # Random forest\n",
        "gtb_classifier = ee.Classifier.smileGradientTreeBoost( # gradient tree boosting\n",
        "    numberOfTrees=50,\n",
        "    shrinkage=0.005,\n",
        "    samplingRate=0.7,\n",
        "    maxNodes=None,\n",
        "    loss='LeastAbsoluteDeviation',\n",
        "    seed=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9vYVLXIa5dZ"
      },
      "source": [
        "## Define the train and classification function\n",
        "This function, train_run_classification, dynamically trains and applies a selected machine learning classifier to classify satellite imagery. It begins by initializing placeholders for the trained classifier and the classified map. Based on the selected_classifier input, the function selects one of four classifiers: KNN, Random Forest,CART (Decision Tree), SVM with an RBF kernel, or Gradient Tree Boost, each configured with appropriate parameters. The chosen classifier is trained using the train_classifier function on the provided training dataset. After training, the function classifies the input features (input_features) using the trained classifier and clips the classified map to the specified boundary. A predefined color palette and visualization parameters are prepared for displaying the classified map. The function returns the trained classifier and the classified map, allowing for both accuracy assessment and visualization. This modular design enables flexible experimentation with different classifiers for land cover or other remote sensing classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hay4UZJzOovu"
      },
      "outputs": [],
      "source": [
        "# Define a function\n",
        "def train_run_classification(selected_classifier, sample_training, bands, boundary):\n",
        "    trained_classifier = None\n",
        "    classified_map = None\n",
        "    palette = [\"grey\", \"red\", \"yellow\", \"lime\", \"green\", \"blue\"]\n",
        "    viz = {\"min\": 0, \"max\": 5, \"palette\": palette}\n",
        "\n",
        "    if selected_classifier == \"KNN\":\n",
        "        knn_classifier = ee.Classifier.smileKNN(k=5)  # Correct initialization for KNN\n",
        "        trained_classifier = train_classifier(knn_classifier, sample_training)\n",
        "        classified_map = input_features.select(bands).classify(trained_classifier).clip(boundary)\n",
        "    elif selected_classifier == \"SVM\":\n",
        "        rbf_svc_classifier = ee.Classifier.libsvm(kernelType='RBF', gamma=0.5)\n",
        "        trained_classifier = train_classifier(rbf_svc_classifier, sample_training)\n",
        "        classified_map = input_features.select(bands).classify(trained_classifier).clip(boundary)\n",
        "    elif selected_classifier == \"CART\":\n",
        "        dt_classifier = ee.Classifier.smileCart()\n",
        "        trained_classifier = train_classifier(dt_classifier, sample_training)\n",
        "        classified_map = input_features.select(bands).classify(trained_classifier).clip(boundary)\n",
        "    elif selected_classifier == \"Random forest\":\n",
        "        rf_classifier = ee.Classifier.smileRandomForest(100)\n",
        "        trained_classifier = train_classifier(rf_classifier, sample_training)\n",
        "        classified_map = input_features.select(bands).classify(trained_classifier).clip(boundary)\n",
        "    elif selected_classifier == \"Gradient tree boost\":\n",
        "        gtb_classifier = ee.Classifier.smileGradientTreeBoost(\n",
        "            numberOfTrees=50, shrinkage=0.005, samplingRate=0.7, maxNodes=None, loss='LeastAbsoluteDeviation', seed=0)\n",
        "        trained_classifier = train_classifier(gtb_classifier, sample_training)\n",
        "        classified_map = input_features.select(bands).classify(trained_classifier).clip(boundary)\n",
        "    else:\n",
        "        print(\"Invalid classifier\")\n",
        "\n",
        "    return trained_classifier, classified_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykeFs0RjbMQF"
      },
      "source": [
        "## Train and perform classification\n",
        "Next, we train six classifiers (KNN, SVM, Decision Tree, Random Forest, and Gradient Tree Boost) using the train_run_classification function and generate classified maps for each. The training uses the stratified training dataset (Sample_training) and the specified bands, while the classified maps are clipped to the boundary region. To visualize the results, the display_map function is defined to create an interactive map using geemap. This function applies a color palette and visualization parameters to the classified map and centers the map on the boundary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gY0HxscO6T-"
      },
      "outputs": [],
      "source": [
        "# Train classifiers and get the classified maps\n",
        "trainedKNN, knn_classified_map = train_run_classification(\"KNN\", Sample_training, bands, boundary)\n",
        "trainedRBFSVC, rbf_svc_classified_map = train_run_classification(\"SVM\", Sample_training, bands, boundary)\n",
        "trainedDT, dt_classified_map = train_run_classification(\"CART\", Sample_training, bands, boundary)\n",
        "trainedRF, rf_classified_map = train_run_classification(\"Random forest\", Sample_training, bands, boundary)\n",
        "trainedGTB, gtb_classified_map = train_run_classification(\"Gradient tree boost\", Sample_training, bands, boundary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsCl4R3wu9Dg"
      },
      "source": [
        "## Display land cover maps\n",
        "Each classified map is displayed with a title corresponding to its classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APC64226qPGE"
      },
      "outputs": [],
      "source": [
        "# Define a function to add a land cover legend\n",
        "def add_legend(map_instance):\n",
        "    legend_dict = {\n",
        "        \"Bare areas\": (128, 128, 128),  # grey\n",
        "        \"Built-up\": (255, 0, 0),        # red\n",
        "        \"Cropland\": (255, 255, 0),      # yellow\n",
        "        \"Grass/open areas\": (0, 255, 0),# lime\n",
        "        \"Woodlands\": (0, 128, 0),       # green\n",
        "        \"Water\": (0, 0, 255),           # blue\n",
        "    }\n",
        "    map_instance.add_legend(legend_title=\"Land Cover Legend\", legend_dict=legend_dict)\n",
        "\n",
        "# Create and display the maps for each classifier with legends\n",
        "def display_map_with_legend(classified_map, title):\n",
        "    map_instance = geemap.Map()\n",
        "    palette = [\"grey\", \"red\", \"yellow\", \"lime\", \"green\", \"blue\"]\n",
        "    viz = {\"min\": 0, \"max\": 5, \"palette\": palette}\n",
        "    map_instance.centerObject(boundary, 12)\n",
        "    map_instance.addLayer(classified_map, viz, title)\n",
        "    map_instance.addLayerControl()\n",
        "    add_legend(map_instance)  # Add the legend to the map\n",
        "    return map_instance\n",
        "\n",
        "# Display each map with a legend\n",
        "map_knn = display_map_with_legend(knn_classified_map, \"KNN classification\")\n",
        "map_rbf_svc = display_map_with_legend(rbf_svc_classified_map, \"SVM (RBF) classification\")\n",
        "map_dt = display_map_with_legend(dt_classified_map, \"Decision tree classification\")\n",
        "map_rf = display_map_with_legend(rf_classified_map, \"Random forest classification\")\n",
        "map_gtb = display_map_with_legend(gtb_classified_map, \"Gradient tree boost classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyEULECkaDfy"
      },
      "source": [
        "### KNN-derived land cover map\n",
        "Display the land cover map derived from the KNN classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvEUfANBaHr8"
      },
      "outputs": [],
      "source": [
        "# Display the land cover map derived from the KNN classifier.\n",
        "map_knn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyQ1q2oXdDQc"
      },
      "source": [
        "### Support vector machine-derived land cover map\n",
        "Display the land cover map derived from the support vector machine (SVM) classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGs8KOW4NqS1"
      },
      "outputs": [],
      "source": [
        "# Display the land cover map derived from the support vector machine (SVM) classifier.\n",
        "map_rbf_svc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGVPUulpcqAk"
      },
      "source": [
        "### Decision tree-derived land cover map\n",
        "Display the land cover map derived from the decision tree classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v37v9cVrNguW"
      },
      "outputs": [],
      "source": [
        "# Display the land cover map derived from the decision tree classifier.\n",
        "map_dt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KPEBiZVc2S7"
      },
      "source": [
        "### Random forest-derived land cover map\n",
        "Display the land cover map derived from the random forest classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVHLaM2KM2F2"
      },
      "outputs": [],
      "source": [
        "# Display the land cover map derived from the random forest classifier.\n",
        "map_rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sWK98k5dPFC"
      },
      "source": [
        "### Gradient tree boost-derived land cover map\n",
        "Display the land cover map derived from the gradient tree boost classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYB66XsoNxjY"
      },
      "outputs": [],
      "source": [
        "# Display the land cover map derived from the gradient boosting classifier.\n",
        "map_gtb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGmT1Rx_eB46"
      },
      "source": [
        "## Classification accuracy assessment\n",
        "Finally, we evaluate the accuracy of classifiers using a test dataset. The compute_metrics function takes a trained classifier, test dataset, and algorithm name as inputs. It applies the classifier to the test data, generating predictions, and then calculates an error matrix that compares predicted classes with reference data. Key metrics such as user accuracy, producer accuracy, and overall accuracy are extracted from the error matrix and printed alongside the algorithm name for clarity. The function is applied to each classifier (minimum distance, decision trees, random forest, RBF support vector machines classifier, and gradient tree boosting) using the test dataset (Sample_test), providing a comprehensive accuracy assessment for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ow9BCDVQ3z6"
      },
      "outputs": [],
      "source": [
        "# Function to compute accuracy metrics\n",
        "def compute_metrics(classifier, validation_data, algorithm_name):\n",
        "    validation_data_classified = validation_data.classify(classifier)\n",
        "    error_matrix = validation_data_classified.errorMatrix('class', 'classification')\n",
        "    print(f'Algorithm: {algorithm_name}')\n",
        "    print('Validation Error Matrix:\\n', error_matrix.getInfo())\n",
        "    print('User Accuracy: ', error_matrix.consumersAccuracy().getInfo())\n",
        "    print('Producer Accuracy: ', error_matrix.producersAccuracy().getInfo())\n",
        "    print('Overall Accuracy: ', error_matrix.accuracy().getInfo())\n",
        "    print('-----------------------------------------------')\n",
        "\n",
        "# Compute metrics for each classifier\n",
        "compute_metrics(trainedKNN, Sample_test, 'KNN')\n",
        "compute_metrics(trainedRBFSVC, Sample_test, 'RBF SVM')\n",
        "compute_metrics(trainedDT, Sample_test, 'Decision trees')\n",
        "compute_metrics(trainedRF, Sample_test, 'Random forest')\n",
        "compute_metrics(trainedGTB, Sample_test, 'Gradient tree boosting')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}